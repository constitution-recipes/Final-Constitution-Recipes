# 8ì²´ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

ë‹¹ì‹ ì´ ê³„íší•˜ëŠ” LangChain + LangGraph ê¸°ë°˜ì˜ 8ì²´ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œì€ **ë‹¤ì¤‘ í„´ ëŒ€í™”**, **ì¡°ê±´ ê¸°ë°˜ ì¶”ë¡ **, **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**, **RAG í†µí•©**, ê·¸ë¦¬ê³  **ì „ë¬¸ê°€ ê²€ìˆ˜**ë¼ëŠ” ë³µí•© ê¸°ëŠ¥ì´ í†µí•©ëœ êµ¬ì¡°ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì•„í‚¤í…ì²˜ì™€ êµ¬í˜„ ì „ëµì„ ì œì•ˆë“œë¦½ë‹ˆë‹¤:

## ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

```mermaid
graph TD
  A[Next.js í”„ë¡ íŠ¸ì—”ë“œ] --> B[LangGraph on LangChain ì„œë²„]
  B --> C1[LLM ë¬¸ì§„ ë…¸ë“œ]
  B --> C2[RAG ì§„ë‹¨ ë…¸ë“œ]
  B --> C3[ì»¨í”¼ë˜ìŠ¤ íŒë‹¨ ë…¸ë“œ]
  B --> C4[ì „ë¬¸ê°€ ê²€ìˆ˜ ì €ì¥]
```

## ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ê³„

### 1. ğŸ§¾ ì‚¬ìš©ì ë¬¸ì§„ ìˆ˜ì§‘ (LLM ëŒ€í™”í˜• ì§ˆë¬¸ ìƒì„±)

- LangGraphì—ì„œ `ë¬¸ì§„ ì§ˆë¬¸ ë…¸ë“œ(questionNode)` ìƒì„±  
- ì´ì „ê¹Œì§€ ìˆ˜ì§‘ëœ `user_answers` ìƒíƒœë¥¼ LLMì— ì „ë‹¬í•´ ë‹¤ìŒ ì§ˆë¬¸ì„ **ìë™ ìƒì„±**  
- LLMì´ ìƒì„±í•œ ì§ˆë¬¸ì„ ì‚¬ìš©ìì—ê²Œ ì „ì†¡í•˜ê³  ì‘ë‹µì„ ê¸°ë‹¤ë¦¼  
- ì´ ê³¼ì •ì„ **ìµœëŒ€ 10íšŒ** ë°˜ë³µí•˜ë©° `question_count`ë¥¼ ì¦ê°€ì‹œí‚´

```json
// LangGraph ìƒíƒœ êµ¬ì¡° ì˜ˆì‹œ
{
  "user_answers": [
    { "question": "...", "answer": "..." },
    // ...
  ],
  "question_count": 4,
  "diagnosis_ready": false,
  "confidence": null
}
```

### 2. ğŸ§  ì²´ì§ˆ ì§„ë‹¨ ë…¸ë“œ (RAG + LLM + JSON ì¶œë ¥)

- ì§ˆë¬¸ì´ 8~10íšŒ í•˜ê³  LLMì´ ì§„ë‹¨ì´ ê°€ëŠ¥í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ `ì§„ë‹¨ ë…¸ë“œ` ì§„ì…  
- RAGë¥¼ ì‚¬ìš©í•´ ì „ë¬¸ê°€ ì‚¬ë¡€ DBì—ì„œ ìœ ì‚¬í•œ íŒ¨í„´ ì°¸ì¡°  
- `constitution_prompt.md`ë¥¼ system promptë¡œ ë¡œë”© + ì‚¬ìš©ì ì‘ë‹µ ë°˜ì˜  
- ì¶œë ¥ í˜•ì‹:

```json
{
  "ì²´ì§ˆ": "ê¸ˆì–‘",
  "ì§„ë‹¨ì´ìœ ": "ê³ ê¸° ì„­ì·¨ í›„ ë¶ˆí¸í•¨, í•´ì‚°ë¬¼ ì„ í˜¸, ì¸ì‚¼ ë¶€ì‘ìš©",
  "confidence": 0.83
}
```

> **LangChainì—ì„œ ì‚¬ìš©í•  RAG ë°©ë²•**  
> - `RetrievalQAChain` ë˜ëŠ” `ConversationalRetrievalChain`  
> - retriever: `VectorStoreRetriever` (ì˜ˆ: Chroma, FAISS)  
> - ì „ë¬¸ê°€ ì‚¬ë¡€ ë°ì´í„°ë¥¼ chunkí•˜ì—¬ embedding

### 3. ğŸ“‰ Low confidence ëŒ€ì‘ ë…¸ë“œ

- ì§„ë‹¨ í›„ `confidence < threshold (ì˜ˆ: 0.7)`ì´ë©´:

#### A. ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì§ˆë¬¸

- LangGraphì—ì„œ ë‹¤ì‹œ `ë¬¸ì§„ ë…¸ë“œ`ë¡œ ë¶„ê¸°  
- "í™•ì‹ ì´ ì–´ë µìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ ì¶”ê°€ ì§ˆë¬¸ ë“œë¦´ê²Œìš”."

#### B. LLMì—ê²Œ ë‹¤ì‹œ ì§„ë‹¨ ì‹œë„

- ì´ì „ ì‘ë‹µ + RAG context ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ `ì§„ë‹¨ ì¬ì‹œë„`

> LangGraphì—ì„œëŠ” `if-else` ë¶„ê¸° ë…¸ë“œë¡œ êµ¬í˜„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### 4. ğŸ“‚ í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

- `constitution_prompt.md`, `diagnosis_prompt_v2.md` ë“± í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ë””ìŠ¤í¬ ë˜ëŠ” Notion ê¸°ë°˜ìœ¼ë¡œ ê´€ë¦¬  
- LangChainì—ì„œ `loadPrompt(template_name)` ë°©ì‹ìœ¼ë¡œ ìœ ì—°í•˜ê²Œ ì—°ê²°

```ts
import { loadPrompt } from "./promptLoader.ts";
const prompt = await loadPrompt("constitution_prompt.md");
```

### 5. ğŸ‘¨â€âš•ï¸ ì „ë¬¸ê°€ ê²€ìˆ˜ ì‹œìŠ¤í…œ

#### êµ¬ì¡°

- ì‚¬ìš©ì ì§ˆë¬¸/ë‹µë³€, ì§„ë‹¨ ê²°ê³¼, RAG ì°¸ê³  ë‚´ìš©, LLM ì§„ë‹¨ ì´ìœ  â†’ í•˜ë‚˜ì˜ JSONìœ¼ë¡œ ì €ì¥

```json
{
  "session_id": "abc123",
  "answers": [ /* ... */ ],
  "diagnosis": {
    "constitution": "ê¸ˆì–‘",
    "confidence": 0.82,
    "reasoning": "..."
  },
  "retrieved_docs": ["ë¬¸ì„œ ìš”ì•½ 1", "ë¬¸ì„œ ìš”ì•½ 2"],
  "llm_prompt": "ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ ë‚´ìš©"
}
```

#### í”„ë¡ íŠ¸ êµ¬í˜„ (Next.js)

- ê´€ë¦¬ì í˜ì´ì§€ì— ëŒ€í™” ê¸°ë¡ í…Œì´ë¸” ì œê³µ  
- ê° ì§„ë‹¨ ê²°ê³¼ í™•ì¸ ë° `ì§„ë‹¨ ìˆ˜ì •` ê¸°ëŠ¥ (ìˆ˜ì • ì‹œ íˆìŠ¤í† ë¦¬ ë³´ì¡´)  
- ìˆ˜ì •ëœ ì²´ì§ˆ ê²°ê³¼ëŠ” `verified_by_expert: true`ë¡œ ê¸°ë¡

### 6. âœ… ì£¼ìš” ê¸°ìˆ  êµ¬ì„±ìš”ì†Œ ìš”ì•½

| êµ¬ì„±            | ë„êµ¬                                            |
| --------------- | ----------------------------------------------- |
| LLM             | OpenAI / Claude / Mistral                        |
| RAG DB          | Chroma / FAISS + LangChain Retriever             |
| LangGraph       | ì§ˆë¬¸ íë¦„ + ì¡°ê±´ ë¶„ê¸° ê´€ë¦¬                       |
| ìƒíƒœ ì €ì¥       | LangChain Graph State                            |
| í”„ë¡¬í”„íŠ¸ ê´€ë¦¬   | JSON í…œí”Œë¦¿ + ë™ì  ë¡œë”                          |
| ê²€ìˆ˜ DB         | MongoDB ë˜ëŠ” Firebase Firestore                  |
| í”„ë¡ íŠ¸ì—”ë“œ      | Next.js + Tailwind + (Prisma ì„ íƒ)               |

## ì¶”ê°€ ê³ ë ¤ ì‚¬í•­

- **ì§ˆë¬¸ ë‹¤ì–‘í™”**: ì§ˆë¬¸ í…œí”Œë¦¿ì„ ë‹¤ì–‘í™”í•˜ì—¬ ì˜¤ë²„í”¼íŒ… ë°©ì§€  
- **ì§„ë‹¨ í”¼ë“œë°± ìˆ˜ì§‘**: ì‚¬ìš©ì í”¼ë“œë°± ë²„íŠ¼ ì œê³µ ("ë§ëŠ” ê²ƒ ê°™ì•„ìš”" / "ì˜ ëª¨ë¥´ê² ì–´ìš”")  
- **ì²´ì§ˆë³„ í†µê³„ ì‹œê°í™”**: ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œì—ì„œ ì²´ì§ˆë³„ ì§„ë‹¨ ë¹„ìœ¨, í‰ê·  confidence ë“± ì œê³µ  
- **LangGraph debug ëª¨ë“œ**: ê° ë¶„ê¸°ì—ì„œ í˜¸ì¶œëœ ë…¸ë“œ ë¡œê¹… ê¸°ëŠ¥ ì œê³µ

## ì˜ˆì‹œ ì§„ë‹¨ íë¦„ (LangGraph ì‹œí€€ìŠ¤)

1. ì‚¬ìš©ì ëŒ€í™” ì‹œì‘ â†’ ì§ˆë¬¸ ë…¸ë“œ ì§„ì…  
2. ìµœëŒ€ 10íšŒ ì§ˆë¬¸/ì‘ë‹µ ì €ì¥  
3. ì§„ë‹¨ ì¡°ê±´ ì¶©ì¡± â†’ RAG + LLMìœ¼ë¡œ ì§„ë‹¨  
4. `confidence < 0.7` â†’ ì¶”ê°€ ì§ˆë¬¸ ë˜ëŠ” ì¬ì§„ë‹¨  
5. JSON ê²°ê³¼ ì €ì¥ + ì „ë¬¸ê°€ ê²€ìˆ˜ DBë¡œ ì „ë‹¬  
6. í”„ë¡ íŠ¸ì—ì„œ ê²°ê³¼ í™•ì¸ ë° ìˆ˜ì • UI ì œê³µ

```mermaid
graph LR
  start([ì‹œì‘]) --> ask(ë¬¸ì§„ ì§ˆë¬¸ ë…¸ë“œ)
  ask --> answer(ì‚¬ìš©ì ì‘ë‹µ ì €ì¥ ë…¸ë“œ)
  answer -->|ì§„ë‹¨_ready? ì•„ë‹ˆì˜¤| ask
  answer -->|ì§„ë‹¨_ready? ì˜ˆ| diagnose(ì§„ë‹¨ ë…¸ë“œ)
  diagnose --> checkConf(ì»¨í”¼ë˜ìŠ¤ íŒë‹¨ ë…¸ë“œ)
  checkConf -->|confidence < 0.85| ask
  checkConf -->|confidence â‰¥ 0.85| save(ê²°ê³¼ ì €ì¥/ì¢…ë£Œ)
```

```python
# âœ… LangGraph íë¦„ ìŠ¤ìºí´ë”© (LangChain + LangGraph ê¸°ë°˜)
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from prompt_loader import load_prompt
from retriever import vectorstore
from langgraph import Graph

llm = ChatOpenAI(model_name="gpt-4", temperature=0)
retriever = vectorstore.as_retriever()

# ìƒíƒœ ì´ˆê¸°ê°’
initial_state = {
  "user_answers": [],
  "question_count": 0,
  "diagnosis_ready": False,
  "confidence": None,
  "diagnosis": None,
}

async def question_node(state):
  questions = await fetch_next_question(state["user_answers"])  # ì§ˆë¬¸ ì„ íƒ ë¡œì§
  state["question"] = questions
  return state

async def answer_node(state, user_answer):
  state["user_answers"].append(user_answer)
  state["question_count"] += 1
  state["diagnosis_ready"] = state["question_count"] >= 10
  return state

async def diagnosis_node(state):
  prompt = load_prompt("constitution_prompt.md")
  rag_chain = RetrievalQA.from_chain_type(
      llm=llm,
      chain_type="stuff",
      retriever=retriever,
      question_prompt=prompt,
  )
  user_input = "\n".join([
      f"Q: {qa['question']}\nA: {qa['answer']}" for qa in state["user_answers"]
  ])
  response = await rag_chain.acall({"query": user_input})
  parsed = json.loads(response["result"])
  state["diagnosis"] = parsed
  state["confidence"] = parsed["confidence"]
  return state

def confidence_node(state):
  return 'reask' if state["confidence"] < 0.7 else 'complete'

graph = Graph()
graph.add_node("ask", question_node)
graph.add_node("answer", answer_node)
graph.add_node("diagnose", diagnosis_node)
graph.add_node("check_confidence", confidence_node)
graph.add_edge("ask", "answer")
graph.add_edge("answer", lambda s: "diagnose" if s["diagnosis_ready"] else "ask")
graph.add_edge("diagnose", "check_confidence")
graph.add_edge("check_confidence", {"reask": "ask", "complete": "save"})
```
| ê¸°ëŠ¥ | HTTP ë©”ì„œë“œ | ê²½ë¡œ | ì„¤ëª… |
|-----------------------------|------------|---------------------------------------|------------------------------------------------------------|
| ì²´ì§ˆ ì§„ë‹¨ í”„ë¡ì‹œ | POST | /api/v1/constitution | LLMì— ì²´ì§ˆ ì§„ë‹¨ ìš”ì²­ â†’ DBì— ê²°ê³¼(ì²´ì§ˆÂ·ì´ìœ Â·ì‹ ë¢°ë„) ì—…ë°ì´íŠ¸ â†’ ì§„ë‹¨ ê²°ê³¼ ë°˜í™˜ |
| ì‚¬ìš©ì-LLM ì±— í”„ë¡ì‹œ | POST | /api/v1/users/chat | í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ë¥¼ LLM ì„œë¹„ìŠ¤ë¡œ í”„ë¡ì‹œ ì „ì†¡ â†’ ì‘ë‹µ ì €ì¥Â·ì „ë‹¬ â†’ ë ˆì‹œí”¼ ìƒì„± ì‹œ ì €ì¥ ì—°ë™ |
| ë ˆì‹œí”¼ ìë™ ìƒì„± | POST | /api/v1/recipes/auto_generate | ì²´ì§ˆ ë° ì„ íƒ í•­ëª© ê¸°ë°˜ìœ¼ë¡œ AI-Data LLMì— ìë™ ë ˆì‹œí”¼ ìƒì„± ìš”ì²­ â†’ ìƒì„±ëœ ë ˆì‹œí”¼ DB ì €ì¥ ë° ë°˜í™˜ |
| ë ˆì‹œí”¼ í†µê³„ ìƒì„± | POST | /api/v1/stats/generate | ì €ì¥ëœ ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ ì§‘ê³„í•´ ì¹´í…Œê³ ë¦¬Â·ë‚œì´ë„Â·ì²´ì§ˆÂ·ì¬ë£Œë³„ í†µê³„ ìƒì„± ë° ì €ì¥ |
| ëª¨ë¸Â·í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ë° ì €ì¥ | POST | /api/v1/experiment/test | ë‹¤ì–‘í•œ ëŒ€í™” ì„¸íŠ¸ë¡œ ëª¨ë¸Â·í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ â†’ í’ˆì§ˆÂ·ë¹„ìš© ì ìˆ˜ ê³„ì‚° â†’ ì‹¤í—˜ ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„° DB ì €ì¥ â†’ ì‘ë‹µ ë°˜í™˜ |